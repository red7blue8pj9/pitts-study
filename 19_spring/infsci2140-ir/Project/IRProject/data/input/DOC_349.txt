https://www.nytimes.com/2017/03/23/business/media/youtube-advertisers-offensive-content.html
YouTube Advertiser Exodus Highlights Perils of Online Ads - The New York Times
META-KEYWORDS NOT FOUND
349
AdvertisementSupported byBy Daisuke Wakabayashi and Sapna MaheshwariWhen Google acquired YouTube in 2006 for $1.65 billion, it was considered a pricey gamble, one made with the belief that an online service known for pirated videos and vapid user-generated content could appeal to major advertisers.The bet paid off. YouTube is now one of the pillars of Google’s advertising business and the most valuable video platform on the internet. In recent years, advertisers, unable to ignore its massive audience, flocked to YouTube to reach younger people who have started to shun traditional broadcast television.But the technology underpinning YouTube’s advertising business has come under intense scrutiny in recent days, with AT&T, Johnson & Johnson and other deep-pocketed marketers announcing that they would pull their ads from the service. Their reason: The automated system in which ads are bought and placed online has too often resulted in brands appearing next to offensive material on YouTube such as hate speech.On Thursday, the ride-sharing service Lyft became the latest example, removing their ads after they appeared next to videos from a racist skinhead group.“This is beyond offensive,” a Lyft spokesman, Scott Coriell, said. “As soon as we learned of it, we pulled our advertising on YouTube.”The pullback from advertisers strikes to the core of YouTube’s appeal. Unlike television, with specific programming during which brands choose to run their advertising, YouTube mirrors the internet’s sprawl, specializing in niche content that may not appeal to a mainstream audience but attracts engaged viewers. This provides YouTube with an enormous audience watching one billion hours of videos a day, perfect for new ad technology that minutely slices and dices an audience so that companies can target specific viewers.That technology, known as programmatic advertising, allows advertisers to lay out the general parameters of what kind of person they want to reach — say, a young man under 25 — and trust that their ad will find that person, no matter where he might be on the internet. This approach plays to the strengths of tech giants like Google and Facebook, allowing advertisers to use automation and data to cheaply and efficiently reach their own audiences, funneling money through a complicated system of agencies and third-party networks.But more than 400 hours of content are uploaded to YouTube every minute, and while Google has noted that it prevents ads from running near inappropriate material “in the vast majority of cases,” it has proved unable to totally police that amount of content in real time. And that has advertisers increasingly concerned.“The simple truth is that the same tech that allows the posting of a recipe, the joyous video of a child or the exposure of an excessive act from law enforcement allows the creation, posting or sharing of the video of a murder,” Rob Norman, the chief digital officer of GroupM, the media buying arm of WPP, wrote this week in Campaign, a trade publication.Marketers have seen programmatic advertising as a groundbreaking development in media — a technologically efficient way to leverage the expanse of the internet so that, for example, Pampers can reach a new mom on a local blog or an instructional video about how to deal with a newborn’s baby acne. This has opened up the whole of the internet to brands, which typically opt to remove their ads after they have appeared on unsavory sites, rather than restrict the ads to a list of preapproved locations.That is a radical departure. Not long ago, brands like Procter & Gamble were in fact funding TV shows such as “Gilmore Girls,” “7th Heaven” and “Sabrina, the Teenage Witch” because they wanted more platforms for “family friendly” content. The main concern for advertisers on the web used to be appearing next to pornography, a fear that still ranks high for some, but now seems almost quaint considering the increasing amount of content tied to terrorism, violence and hate speech.It’s not limited to YouTube — automated advertising has landed airline ads on news stories about plane crashes, enabled counterfeit clothing companies to flourish on Facebook and even put money in the hands of Russian cybercriminals. Most recently, it has contributed to the proliferation of so-called fake news and conspiracy theories.“I distinctly remember doing presentations years and years ago, and there was some stat at the time that there were a million ad-supported websites and I thought that was mind-blowing,” said Eric Franchi, co-founder of Undertone, an ad technology company. “Now fast-forward to 2017, and Google’s display network alone has two million sites. It’s a lot harder to maintain brand safety today than what it was because of the sheer number of sites coming into these exchanges every day.”That sheer scale, coupled with its reliance on algorithms rather than humans to filter out the objectionable content after it appears, has been Google’s main defense. More than two million websites are a part of its display advertising network — the equivalent of one for every resident of Delaware and Rhode Island combined.“What we do is, we match ads and the content, but because we source the ads from everywhere, every once in a while somebody gets underneath the algorithm and they put in something that doesn’t match. We’ve had to tighten our policies and actually increase our manual review time, and so I think we’re going to be O.K.,” Eric Schmidt, chairman of Google’s parent company, Alphabet, said in an interview on Thursday with Fox Business Network.While brands have expressed concern about showing up next to unsavory photos and videos uploaded to digital platforms by users — like pornography on Snapchat — the situation with YouTube is particularly jarring. YouTube splits advertising revenue with its users, meaning advertisers risk directly funding creators of hateful, misogynistic or terrorism-related content.The revenue-sharing model has minted stars, some of whom gain cultlike followings for edgy and inappropriate content. Last month, the platform cut business ties with its biggest star, Felix Kjellberg, known to his 54 million subscribers as PewDiePie, after The Wall Street Journal reported on crude anti-Semitic jokes and Nazi imagery in his comedy videos. He was part of YouTube’s premium advertising product called Google Preferred — a category of popular, “brand safe” videos on YouTube.The latest black eye came from the far less visible trenches of the platform, as The Times of London reported on ads from prominent brands and the British government appearing on YouTube videos posted by extremist groups.Google has pledged that YouTube will tighten safeguards against ads showing up alongside “hateful, offensive and derogatory content” while reviewing guidelines for what type of content is allowable on the platform.“While we recognize that no system will be 100 percent perfect, we believe these major steps will further safeguard our advertisers’ brands, and we are committed to being vigilant and continuing to improve over time,” Philipp Schindler, Google’s chief business officer, said in a statement on Thursday.There’s a lot at stake for YouTube and Alphabet. Search advertising is not growing as fast as it once did, and television ad budgets are still larger than total spending on digital advertising. YouTube and Facebook have made no secret of their desire for television advertising funds. Internet ad revenue in the United States, which is growing quickly, reached about $60 billion in 2015 while television accounted for about $66 billion, according to a study from IAB and PwC.James Dix, a senior media analyst at Wedbush Securities, estimates that YouTube accounted for revenue of about $13 billion, or roughly 20 percent of all advertising revenue on Google’s internet properties in 2016. Alphabet does not disclose YouTube revenue.“If this company is going to look for new growth at scale, it has to pull money from television,” Mr. Dix said. “Period.”Advertisement
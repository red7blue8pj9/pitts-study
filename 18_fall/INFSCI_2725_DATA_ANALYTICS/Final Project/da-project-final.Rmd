# Data Analytic Term Project
## Titanic: Machine Learning from Disaster
###### Jing Pang, Tian Xue, Chuqian Ma, Jiaxiang Leng

### Introduction
This report describes what we have predicted in Titanic: Machine Learning from Disaster in Data Analytic Class. We use R language as our tool for data analysis and prediction. Our goal is to get more than 75% accuracy. 

### Data processing
We found these 12 features of each passenger in our dataset: PassengerID, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked. Among all these features, some of them are completely recorded, but three of them are missing specific values, in which case we need to conduct prediction to fulfill them for our reference while creating a model. The rest of them need aggregation to get the data to make more sense.

#### Data Analysis and Preparation
We create a new feature column that combines training data and test data. As there is no “survived” column in the test set, creating a new column for saved the result and replace it with NA, and then combined by rows.

1. Feature column 1: Title
As we have found in name column, there are titles which reveal identity information, such as Mr., Mrs., Dr., etc. included in passengers’ names.
We also findd that there are some titles not commonly used in English, like Mlle and Mme, after looking up more information, we also classified them by gender.
We assume that survival is based on passengers' social status and gender based on their title. Thus we reaggregate the category. 

2. Feature column 2: TicketCount
Our group assumed that passengers with the same ticket number come from the same family and may survive or die at the same time. We account the number of passengers each ticket matched and then divide all passengers into two groups according to their ticket numbers. We define one group who use separate ticket number, and the other who share same ticket number with others. 

3. Feature column 3: FamilySize, FamilyID
SibSp and Parch point out that the number of family members may influence the survival of passengers. The larger the family, the  higher the probability that they will die at the same time. So we combined variables SibSp and Parch into a new variable “FamilySize”. We extract the last name of the passenger from the name column and combine it with “FamilySize” to find the family.

### Data Completion
In the train data set, some features have missing values, which will impact the data model training and prediction. Hence, we will try to predict the missing data value based on the previous analysis. In this case, the following paragraphs will go through the features which contain missing values.

#### Age 
The feature age has 263 missing values in total 1309 records. We used the method of analysis of variance, which based on other features: Pclass, Sex, SibSp, Parch, Fare, Embarked, Title and FamilySize, as a baseline to complete the missing age value. 
Later on, after using this new age feature tested in a data model, we consider a new method of completion of missing age by using random forest mode on the same features.

#### Fare
There is only one missing value in feature Fare. Based on previous data analysis, we merely fill this missing data with the median of whole Fare data.

#### Embarked
The Embarked feature has two missing values, and from the data listed, we find that both passengers with missing embarked values are in the Pclass 1 and with Fare 80. Therefore, we consider completing this missing value with the median Embarked value of passengers who have Pclass 1 and Fare 80, which is “C”. 
 
#### Cabin
The feature Cabin has too many missing values in the data, and over 77% of data is missing. Therefore, it is not realistic to complete them with proper prediction values. We decide to ignore them and do not use them in the model training.

### Model Application
From what we have learned in class, we applied logistic regression and random forest models to train our data set. The results turned out that random forest leads to higher precision.

### Conclusion
In order to get over 75% prediction accuracy, we first aggregate data from original 12 features of the data set. We assume that the survival of passengers is influenced by titles, ticket count, and family size. We get the passengers' titles from their names, separate the data set into two groups: single and family based on whether they hold the same ticket number, and finally, we count the family size according to last name derived from name column and separate the group into small family and large family based on whether there are more than two members in a family.
After recategorizing data, we need to fill all the missing values in the data set. We use anova method to predict missing age values, the median to predict fare, and set missing values of Embarked to value C  from the box plot we generate. Finally, we use random forest and logistic regression to get the prediction result based on what we have analyzed above. We get the accuracy of 81.8% as the result.

Referenece

```{r warning=FALSE}
# import preparation
library("rpart") 
library("ggplot2")
library("ggthemes")
library("scales")
library("plyr")
library("dplyr")
library("mice")
library("randomForest")
library("party")
library("corrplot")	

# import data into R 
train <- read.csv("~/R-workspace/train.csv")
test <- read.csv("~/R-workspace/test.csv")

# summary of both data
summary(train)
summary(test)

```


```{r warning=FALSE}

# preparate combination of train and test 
test$Survived<-NA
combi<-rbind(train,test)

# characterise the data
mode(combi$Name)
combi$Name<-as.character(combi$Name)

# create a new feature - title
combi$Title<-sapply(combi$Name, FUN=function(x){strsplit(x,split='[,.]')[[1]][2]})
# remove the empty space
combi$Title<-sub(' ','',combi$Title)
# replace french title as english 
combi$Title[combi$Title %in% c('Mme', 'Mlle')] <- 'Mlle'
combi$Title[combi$Title %in% c('Capt', 'Don', 'Major', 'Sir')] <- 'Sir'
combi$Title[combi$Title %in% c('Dona', 'Lady', 'the Countess', 'Jonkheer')] <- 'Lady'
combi$Title <- factor(combi$Title)

# create a new feature - ticket count
# analysis ticket feature
ticket.count <- aggregate(combi$Ticket, by = list(combi$Ticket), function(x)sum(!is.na(x)))
combi$TicketCount <- apply(combi, 1, function(x) 
ticket.count[which(ticket.count[, 1] == x['Ticket']), 2]
)
# form new feature ticket count
combi$TicketCount <- factor(sapply(combi$TicketCount, function(x) 
ifelse(x > 1, 'Share', 'Unique')))   ## ifelse(test, yes, no)

# create a new feature - family size
combi$FamilySize <- combi$SibSp + combi$Parch + 1

# create a new feature - family id
combi$Surname <- sapply(combi$Name, FUN=function(x) {strsplit(x, split='[,.]')[[1]][1]})
combi$FamilyID <- paste(as.character(combi$FamilySize), combi$Surname, sep="")
combi$FamilyID[combi$FamilySize <= 2] <- 'Small'
famIDs <- data.frame(table(combi$FamilyID))

famIDs <- famIDs[famIDs$Freq <= 2,]
combi$FamilyID[combi$FamilyID %in% famIDs$Var1] <- 'Small' 
## FamilySize>2 Freq<=2
combi$FamilyID <- factor(combi$FamilyID)

# list all NA value
sapply(combi,function(x) sum(is.na(x)))
sapply(combi,function(x) sum(x==""))

# fullfil missing value 
# Age feature
## age test 1 
age_model_1 <- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked + Title + FamilySize, data=combi[!is.na(combi$Age),], method="anova")
combi$Age1[is.na(combi$Age)] <- predict(age_model_1, combi[is.na(combi$Age),])
## age test 2 
set.seed(129)
ss <- c('PassengerId','Name','Ticket','Cabin','family','Surname','Survived')
mice_age <- mice(combi[,!names(combi) %in% ss],method = 'rf')
mice_output <- complete(mice_age)
# plot age graph
par(mfrow=c(1,2))
hist(combi$Age,freq = F,main = 'Age:ORiginal Data',col='darkblue',ylim = c(0,0.04))
hist(mice_output$Age,freq = F,main = 'Age:MICE Output',col = 'skyblue',ylim = c(0,0.04))
# add new feature - age_2
combi$Age2 <- mice_output$Age


# Fare feature
combi$Fare[is.na(combi$Fare)] <- median(combi$Fare, na.rm=TRUE)

# Embarked feature
# Embarked only two value
combi$Embarked[is.na(combi$Embarked)] <- 'C'
combi$Embarked<-factor(combi$Embarked)


```

```{r warning=FALSE}
ggplot(combi[!is.na(combi$Embarked),], aes(x=Embarked, y=Fare, fill=factor(Pclass))) +
  geom_boxplot() +
  geom_hline(aes(yintercept=80), color='red', linetype='dashed', lwd=2) +
  scale_y_continuous(labels=dollar_format()) + theme_few()
```

```{r warning=FALSE}
# prepare the modification dataset train_df and test_df
train_df <- combi[1:891,]
test_df <- combi[892:1309,]
```

```{r warning=FALSE}

# logistic regression
fit_lg <- glm(Survived ~ Pclass + Sex + Age2 + Fare + Embarked + 
                 Title + FamilySize + TicketCount,
               data = train_df, family = binomial)
pred_lg <- predict(fit_lg, type="response", newdata=test_df)
pred_lg <- ifelse(pred_lg > 0.5,1,0)
res_lg <- data.frame(PassengerId = test_df$PassengerId, Survived = pred_lg)
write.csv(res_lg, file = "res_lg.csv", row.names = FALSE)
```


```{r warning=FALSE}

# random forest 
set.seed(1234)
# test with age1
fit1 <- cforest(as.factor(Survived) ~ Pclass + Sex + Age1 + Fare + Embarked + 
                 Title + FamilySize + TicketCount + FamilyID,
               data = train_df, controls = cforest_unbiased(ntree=2000,mtry=3))
pred_rfmode1 <- predict(fit1, newdata=test_df)
res_rfmode1 <- data.frame(PassengerId = test_df$PassengerId, Survived = pred_rfmode1)
write.csv(res_rfmode1, file = "res-rf-1.csv", row.names = FALSE)
# test with age2
fit2 <- cforest(as.factor(Survived) ~ Pclass + Sex + Age2 + Fare + Embarked + 
                 Title + FamilySize + TicketCount + FamilyID,
               data = train_df, controls = cforest_unbiased(ntree=2000,mtry=3))


pred_rfmode2 <- predict(fit2, newdata=test_df)
res_rfmode2 <- data.frame(PassengerId = test_df$PassengerId, Survived = pred_rfmode2)
write.csv(res_rfmode2, file = "res-rf-2.csv", row.names = FALSE)

```






